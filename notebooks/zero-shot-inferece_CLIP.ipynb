{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33783,"status":"ok","timestamp":1698227981455,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"},"user_tz":-330},"id":"e-jYw8uyrxQE","outputId":"2d8b7830-f922-4a1b-a98e-6d1a8cd214b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1698227986518,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"},"user_tz":-330},"id":"q4pLKkYLt7fq","outputId":"364ab26c-c344-4750-9ed8-d28142f47f22"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Food Recognition Project\n"]}],"source":["%cd /content/drive/MyDrive/Food Recognition Project"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1698227989676,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"},"user_tz":-330},"id":"Wi_6VGKKaRx1","outputId":"c7bc2a22-9f66-4b3d-e86b-de9fc106b1e5"},"outputs":[{"output_type":"stream","name":"stdout","text":[" background_removal.ipynb   CLIP_FM.ipynb   New_Output\t Output  'Resized Dataset'\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jLoFP8uwXfce"},"outputs":[],"source":["!conda install --yes -c pytorch pytorch=1.7.1 torchvision cudatoolkit=11.0\n","!pip install ftfy regex tqdm\n","!pip install git+https://github.com/openai/CLIP.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8VHpHMF2H1iR"},"outputs":[],"source":["!pip install torch torchvision transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xQveb2nnL_8n"},"outputs":[],"source":["import os\n","import clip\n","import torch\n","from PIL import Image\n","import pandas as pd\n","import random\n","import glob\n","import numpy as np\n","from tqdm import tqdm\n","\n","device = \"cpu\"\n","model, preprocess = clip.load('ViT-B/32', device)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OQy7qSpYmM20"},"outputs":[],"source":["from multiprocessing import Pool"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1698144967302,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"},"user_tz":-330},"id":"M69lLbUoXK5E","outputId":"a540062c-998b-464c-c4a1-44fafd363406"},"outputs":[{"name":"stdout","output_type":"stream","text":["The number of pools available is: 2\n"]}],"source":["import multiprocessing\n","import os\n","pool_count = multiprocessing.cpu_count()\n","print(f'The number of pools available is: {pool_count}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uygja9jSaxtk"},"outputs":[],"source":["#Creating Dataframes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1698048685171,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"},"user_tz":-330},"id":"s3nOtXDGFTdL","outputId":"6f5f152b-0b50-424d-c8ef-de3ae8e97f2a"},"outputs":[{"data":{"text/plain":["['commercial_air_normal',\n"," 'commercial_air_over',\n"," 'commercial_deep_normal',\n"," 'commercial_deep_over',\n"," 'commercial_unbaked',\n"," 'inhouse_air_normal',\n"," 'inhouse_air_over',\n"," 'inhouse_deep_normal',\n"," 'inhouse_deep_over',\n"," 'inhouse_old_air_normal',\n"," 'inhouse_old_air_over',\n"," 'inhouse_old_deep_normal',\n"," 'inhouse_old_deep_over',\n"," 'inhouse_unbaked']"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["class_names = os.listdir('./Resized Dataset/')\n","class_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wHaJu_v_a00m"},"outputs":[],"source":["\n","# Define the root directory of your dataset\n","dataset_root = 'Resized Dataset'\n","\n","# Create an empty dictionary to store dataframes for each class\n","class_dataframes = {}\n","\n","\n","class_folders = sorted(os.listdir(dataset_root))\n","for class_folder in class_folders:\n","    class_path = os.path.join(dataset_root, class_folder)\n","\n","    class_data = []\n","\n","    # Loop through images in each class folder\n","    # Select random 200 images from the class\n","    rand200_images = random.sample(os.listdir(class_path), 200)\n","    for image_file in rand200_images:\n","        image_path = os.path.join(class_path, image_file)\n","\n","\n","        class_data.append({\n","            'ImagePath': image_path,\n","            'Class': class_folder,\n","            'Predicted Class R1': None,\n","            'Predicted Class R3': None,\n","            'Predicted Class R5': None,\n","        })\n","\n","    class_df = pd.DataFrame(class_data)\n","\n","    class_dataframes[class_folder] = class_df\n","\n","print(class_dataframes['commercial_air_normal'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SJyBTGFqJn5V"},"outputs":[],"source":["print(class_dataframes['commercial_air_normal'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tkuZq90B9iaM"},"outputs":[],"source":["candidate_captions = ['A picture of ' + class_name for class_name in class_names]\n","print(candidate_captions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PFhb03XKXNp-"},"outputs":[],"source":["# Test\n","import glob\n","\n","\n","def argmax(iterable):\n","  return max(enumerate(iterable), key=lambda x: x[1])[0]\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model, preprocess = clip.load(\"ViT-B/32\", device=device)\n","\n","correct = []\n","\n","text = clip.tokenize(candidate_captions).to(device)\n","\n","for cls in class_names:\n","  class_correct = []\n","  test_imgs = glob.glob('./Test/' + cls + '/*.jpg')\n","  for img in test_imgs:\n","    image = preprocess(Image.open(img)).unsqueeze(0).to(device)\n","    with torch.no_grad():\n","        image_features = model.encode_image(image)\n","        text_features = model.encode_text(text)\n","\n","        logits_per_image, logits_per_text = model(image,text)\n","        probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n","        print(probs)\n","        pred = class_names[argmax(list(probs)[0])]\n","\n","        if pred == cls:\n","          correct.append(1)\n","          class_correct.append(1)\n","        else:\n","          correct.append(0)\n","          class_correct.append(0)\n","\n","  print('Accuracy on class ' + cls + ' is: ' + str(sum(class_correct)/len(class_correct)))\n","print('Accuracy on all is: ' + str(sum(correct)/len(correct)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jku0Dv5X41UD"},"outputs":[],"source":["def top_n_classes(iterable, n, class_names):\n","    # Get the indices of the top n classes as per the probability\n","    top_indices = sorted(range(len(iterable[0])), key=lambda i: iterable[0][i], reverse=True)[:n]\n","\n","    # Get the corresponding class names\n","    top_class_names = [class_names[i] for i in top_indices]\n","\n","    return top_class_names\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NTA_ICtb0oSv"},"outputs":[],"source":["\n","def runCLIP(cls, candidate_captions, class_dataframes, class_names):\n","\n","  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","  model, preprocess = clip.load(\"ViT-B/32\", device=device)\n","\n","\n","  text = clip.tokenize(candidate_captions).to(device)\n","\n","  for index, row in class_dataframes[cls].iterrows():\n","    curr_image_path = row[\"ImagePath\"]\n","    image = preprocess(Image.open(curr_image_path)).unsqueeze(0).to(device)\n","    with torch.no_grad():\n","        image_features = model.encode_image(image)\n","        text_features = model.encode_text(text)\n","\n","        logits_per_image, logits_per_text = model(image,text)\n","        probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n","\n","\n","        # Adding the predicted class to dataframe R1\n","        predR1 = top_n_classes(probs, 1, class_names)\n","        class_dataframes[cls].at[index, 'Predicted Class R1'] = predR1\n","\n","        # Adding the predicted class to dataframe R3\n","        predR3 = top_n_classes(probs, 3, class_names)\n","        class_dataframes[cls].at[index, 'Predicted Class R3'] = predR3\n","\n","        # Adding the predicted class to dataframe R5\n","        predR5 = top_n_classes(probs, 5, class_names)\n","        class_dataframes[cls].at[index, 'Predicted Class R5'] = predR5\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"79QPWiF9CWJG"},"outputs":[],"source":["# Calculating R1 Accuracy\n","def R1_Accuracy(class_names, class_dataframes):\n","  for cls in class_names:\n","    curr_df =  class_dataframes[cls]\n","\n","\n","    curr_df['R1 Matches'] = curr_df.apply(lambda row: row['Predicted Class R1'][0] == row['Class'], axis=1)\n","    correct_predictions = curr_df['R1 Matches'].sum()\n","    total_predictions = len(curr_df)\n","    accuracy = (correct_predictions / total_predictions) * 100\n","\n","    print(f\"The accuracy of {cls} is {accuracy:f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ffOQ6gC6mPVk"},"outputs":[],"source":["# Calculating R3 Accuracy\n","def R3_Accuracy(class_names, class_dataframes):\n","  for cls in class_names:\n","      curr_df = class_dataframes[cls]\n","\n","      curr_df['R3 Matches'] = curr_df.apply(lambda row: any(class_value == row['Class'] for class_value in row['Predicted Class R3']), axis=1)\n","      correct_predictions = curr_df['R3 Matches'].sum()\n","      total_predictions = len(curr_df)\n","      accuracy = (correct_predictions / total_predictions) * 100\n","\n","      print(f\"The accuracy of {cls} is {accuracy:f}%\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yLXy47I3miRD"},"outputs":[],"source":["# Calculating R5 Accuracy\n","def R5_Accuracy(class_names, class_dataframes):\n","  for cls in class_names:\n","      curr_df = class_dataframes[cls]\n","\n","      curr_df['R5 Matches'] = curr_df.apply(lambda row: any(class_value == row['Class'] for class_value in row['Predicted Class R5']), axis=1)\n","      correct_predictions = curr_df['R5 Matches'].sum()\n","      total_predictions = len(curr_df)\n","      accuracy = (correct_predictions / total_predictions) * 100\n","\n","      print(f\"The accuracy of {cls} is {accuracy:f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J9pcd6uSLmqK"},"outputs":[],"source":["# Saving the Reultant Dataframes as csv\n","def save(output_directory, class_dataframes):\n","  # output_directory = './Output/'\n","\n","  for class_name, df in class_dataframes.items():\n","\n","      output_file_path = f\"{output_directory}{class_name}.csv\"\n","\n","      # Save the DataFrame to a CSV file\n","      df.to_csv(output_file_path, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s5az9yXp52ew"},"outputs":[],"source":["# Running CLIP for all classes\n","for cls in tqdm(class_names):\n","  runCLIP(cls, candidate_captions, class_dataframes, class_names)\n","\n","R1_Accuracy(class_names, class_dataframes)\n","R3_Accuracy(class_names, class_dataframes)\n","R5_Accuracy(class_names, class_dataframes)\n","save('./Output/', class_dataframes)"]},{"cell_type":"markdown","metadata":{"id":"HdZ0ArCbclmc"},"source":["\n","# Removing Redundant classes and Running Clip on them (Final 8 classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2pfDCgmnomH6"},"outputs":[],"source":["new_class_names = ['commercial_deep_normal',\n"," 'commercial_deep_over',\n"," 'commercial_unbaked',\n"," 'inhouse_deep_normal',\n"," 'inhouse_deep_over',\n"," 'inhouse_old_deep_normal',\n"," 'inhouse_old_deep_over',\n"," 'inhouse_unbaked']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1698228739707,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"},"user_tz":-330},"id":"-8KETRCi1TEk","outputId":"c047cfdc-de03-41a0-e466-b356d9461ec5"},"outputs":[{"output_type":"stream","name":"stdout","text":["['A picture of commercial_deep_normal', 'A picture of commercial_deep_over', 'A picture of commercial_unbaked', 'A picture of inhouse_deep_normal', 'A picture of inhouse_deep_over', 'A picture of inhouse_old_deep_normal', 'A picture of inhouse_old_deep_over', 'A picture of inhouse_unbaked']\n"]}],"source":["new_candidate_captions = ['A picture of ' + class_name for class_name in new_class_names]\n","print(new_candidate_captions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2en1Ugtw1ka6"},"outputs":[],"source":["# Define the root directory of your dataset\n","dataset_root = 'Resized Dataset'\n","\n","# Create an empty dictionary to store dataframes for each class\n","new_class_dataframes = {}\n","\n","class_folders = sorted(os.listdir(dataset_root))\n","new_class_folders = [folder for folder in class_folders if folder in new_class_names]\n","\n","for class_folder in new_class_folders:\n","    class_path = os.path.join(dataset_root, class_folder)\n","\n","    class_data = []\n","\n","    # Loop through images in each class folder\n","    # Select random 200 images from the class\n","    rand200_images = random.sample(os.listdir(class_path), 200)\n","    for image_file in rand200_images:\n","        image_path = os.path.join(class_path, image_file)\n","\n","\n","        class_data.append({\n","            'ImagePath': image_path,\n","            'Class': class_folder,\n","            'Predicted Class R1': None,\n","            'Predicted Class R3': None,\n","            'Predicted Class R5': None,\n","        })\n","\n","    class_df = pd.DataFrame(class_data)\n","\n","    new_class_dataframes[class_folder] = class_df\n","\n","print(new_class_dataframes['commercial_deep_normal'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"HjtXXbOc4DjY","outputId":"03a99c55-84bb-4261-c42a-c43c653eb15d"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 8/8 [1:16:36<00:00, 574.52s/it]\n"]}],"source":["for cls in tqdm(new_class_names):\n","  runCLIP(cls, new_candidate_captions, new_class_dataframes, new_class_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2vlrvLotZpxy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698151924114,"user_tz":-330,"elapsed":5,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"}},"outputId":"999c1486-2985-40ba-f0f4-faaf0140ced1"},"outputs":[{"output_type":"stream","name":"stdout","text":["The accuracy of commercial_deep_normal is 0.000000%\n","The accuracy of commercial_deep_over is 0.000000%\n","The accuracy of commercial_unbaked is 98.500000%\n","The accuracy of inhouse_deep_normal is 0.000000%\n","The accuracy of inhouse_deep_over is 0.000000%\n","The accuracy of inhouse_old_deep_normal is 0.000000%\n","The accuracy of inhouse_old_deep_over is 0.000000%\n","The accuracy of inhouse_unbaked is 40.000000%\n"]}],"source":["R1_Accuracy(new_class_names, new_class_dataframes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g0cZqvhLX5Bf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698151930537,"user_tz":-330,"elapsed":390,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"}},"outputId":"e7e6cd53-febd-4a22-8ecd-86a4121806c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["The accuracy of commercial_deep_normal is 3.000000%\n","The accuracy of commercial_deep_over is 71.500000%\n","The accuracy of commercial_unbaked is 100.000000%\n","The accuracy of inhouse_deep_normal is 0.500000%\n","The accuracy of inhouse_deep_over is 18.000000%\n","The accuracy of inhouse_old_deep_normal is 2.000000%\n","The accuracy of inhouse_old_deep_over is 14.500000%\n","The accuracy of inhouse_unbaked is 100.000000%\n"]}],"source":["R3_Accuracy(new_class_names, new_class_dataframes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m89EOFTFakqB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698151934710,"user_tz":-330,"elapsed":390,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"}},"outputId":"2ebeca6a-3f86-433b-c5bd-ce90553a1d11"},"outputs":[{"output_type":"stream","name":"stdout","text":["The accuracy of commercial_deep_normal is 89.500000%\n","The accuracy of commercial_deep_over is 88.500000%\n","The accuracy of commercial_unbaked is 100.000000%\n","The accuracy of inhouse_deep_normal is 15.000000%\n","The accuracy of inhouse_deep_over is 86.000000%\n","The accuracy of inhouse_old_deep_normal is 18.500000%\n","The accuracy of inhouse_old_deep_over is 53.000000%\n","The accuracy of inhouse_unbaked is 100.000000%\n"]}],"source":["R5_Accuracy(new_class_names, new_class_dataframes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7CgcUCWkau6-"},"outputs":[],"source":["save('./New_Output/', new_class_dataframes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hwIauJs2ouxi"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# Analysis of the remaining 6 classes\n"],"metadata":{"id":"b0cPKdgjQqma"}},{"cell_type":"code","source":["remaining_class_names =['commercial_air_normal',\n"," 'commercial_air_over',\n"," 'inhouse_air_normal',\n"," 'inhouse_air_over',\n"," 'inhouse_old_air_normal',\n"," 'inhouse_old_air_over']"],"metadata":{"id":"YtZhmwruQx1i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the root directory of your dataset\n","dataset_root = 'Resized Dataset'\n","\n","# Create an empty dictionary to store dataframes for each class\n","remaining_class_dataframes = {}\n","\n","class_folders = sorted(os.listdir(dataset_root))\n","remaining_class_folders = [folder for folder in class_folders if folder in remaining_class_names]\n","\n","for class_folder in remaining_class_folders:\n","    class_path = os.path.join(dataset_root, class_folder)\n","\n","    class_data = []\n","\n","    # Loop through images in each class folder\n","    # Select random 200 images from the class\n","    rand200_images = random.sample(os.listdir(class_path), 200)\n","    for image_file in rand200_images:\n","        image_path = os.path.join(class_path, image_file)\n","\n","\n","        class_data.append({\n","            'ImagePath': image_path,\n","            'Class': class_folder,\n","            'Predicted Class R1': None,\n","            'Predicted Class R3': None,\n","            'Predicted Class R5': None,\n","        })\n","\n","    class_df = pd.DataFrame(class_data)\n","\n","    remaining_class_dataframes[class_folder] = class_df\n","\n","print(remaining_class_dataframes['commercial_air_normal'])\n"],"metadata":{"id":"SIhX0NLMTHst"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for cls in tqdm(remaining_class_names):\n","  runCLIP(cls, new_candidate_captions, remaining_class_dataframes, new_class_names)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aj8jKg7vTgVj","executionInfo":{"status":"ok","timestamp":1698233515686,"user_tz":-330,"elapsed":3743694,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"}},"outputId":"2e497a3f-3c32-47c0-b62f-f16d3d9c1937"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 6/6 [1:02:23<00:00, 623.90s/it]\n"]}]},{"cell_type":"code","source":["save('./Remaining_Output/', remaining_class_dataframes)"],"metadata":{"id":"CGBJ9dFBUFL9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SdgF-UVhX0g2"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}