{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"K3YzubE29eJS"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"JJAFgf80OrKz"},"source":["# Grounded SAM setection and segmentation of Plant based patties\n"]},{"cell_type":"markdown","metadata":{"id":"SBfaf31fPI3H"},"source":["## Installation and Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_BV7Q55X0o5D"},"outputs":[],"source":["%cd /content\n","\n","!git clone https://github.com/IDEA-Research/Grounded-Segment-Anything\n","\n","%cd /content/Grounded-Segment-Anything\n","\n","!git checkout b579761a11ffab025d75a0f84a2d8a722abf7d5e\n","\n","!pip install -q -r requirements.txt\n","%cd /content/Grounded-Segment-Anything/GroundingDINO\n","!pip install -q .\n","%cd /content/Grounded-Segment-Anything/segment_anything\n","!pip install -q .\n","%cd /content/Grounded-Segment-Anything"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RYdAYPjE-hcF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700594076579,"user_tz":-330,"elapsed":8172,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"}},"outputId":"27bc3271-1cc6-45c6-ad94-135e537f25e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n"]}],"source":["!pip install tqdm"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"3VbZI2A90_sX","executionInfo":{"status":"ok","timestamp":1700594091509,"user_tz":-330,"elapsed":9795,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"}}},"outputs":[],"source":["import os, sys\n","\n","sys.path.append(os.path.join(os.getcwd(), \"GroundingDINO\"))\n","\n","import argparse\n","import copy\n","\n","from IPython.display import display\n","from PIL import Image, ImageDraw, ImageFont\n","from torchvision.ops import box_convert\n","\n","# Grounding DINO\n","import GroundingDINO.groundingdino.datasets.transforms as T\n","from GroundingDINO.groundingdino.models import build_model\n","from GroundingDINO.groundingdino.util import box_ops\n","from GroundingDINO.groundingdino.util.slconfig import SLConfig\n","from GroundingDINO.groundingdino.util.utils import clean_state_dict, get_phrases_from_posmap\n","from GroundingDINO.groundingdino.util.inference import annotate, load_image, predict\n","\n","import supervision as sv\n","\n","# segment anything\n","from segment_anything import build_sam, SamPredictor\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","# diffusers\n","import PIL\n","import requests\n","import torch\n","from io import BytesIO\n","from diffusers import StableDiffusionInpaintPipeline\n","\n","\n","from huggingface_hub import hf_hub_download"]},{"cell_type":"markdown","metadata":{"id":"9-merCSBPM2z"},"source":["## Load Models"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"O0mkiUcG1Q4V","executionInfo":{"status":"ok","timestamp":1700594165993,"user_tz":-330,"elapsed":1118,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"}}},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"HlT07FSbPdL2"},"source":["Grounding DINO model"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"-m7rCocs1cMA","executionInfo":{"status":"ok","timestamp":1700594168662,"user_tz":-330,"elapsed":2,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"}}},"outputs":[],"source":["def load_model_hf(repo_id, filename, ckpt_config_filename, device='cpu'):\n","    cache_config_file = hf_hub_download(repo_id=repo_id, filename=ckpt_config_filename)\n","\n","    args = SLConfig.fromfile(cache_config_file)\n","    args.device = device\n","    model = build_model(args)\n","\n","    cache_file = hf_hub_download(repo_id=repo_id, filename=filename)\n","    checkpoint = torch.load(cache_file, map_location=device)\n","    log = model.load_state_dict(clean_state_dict(checkpoint['model']), strict=False)\n","    print(\"Model loaded from {} \\n => {}\".format(cache_file, log))\n","    _ = model.eval()\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"scru2X9X1kjK"},"outputs":[],"source":["ckpt_repo_id = \"ShilongLiu/GroundingDINO\"\n","ckpt_filenmae = \"groundingdino_swinb_cogcoor.pth\"\n","ckpt_config_filename = \"GroundingDINO_SwinB.cfg.py\"\n","\n","\n","groundingdino_model = load_model_hf(ckpt_repo_id, ckpt_filenmae, ckpt_config_filename, device)"]},{"cell_type":"markdown","metadata":{"id":"vlKMQW5qPhIa"},"source":["SAM model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cmlJQtZM1kmQ"},"outputs":[],"source":["! wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n","\n","sam_checkpoint = 'sam_vit_h_4b8939.pth'\n","\n","sam_predictor = SamPredictor(build_sam(checkpoint=sam_checkpoint).to(device))"]},{"cell_type":"markdown","metadata":{"id":"_lB2Akf4P5KI"},"source":["## Grounding DINO for detection"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"mp50OOvVMkRJ","executionInfo":{"status":"ok","timestamp":1700594255063,"user_tz":-330,"elapsed":780,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"}}},"outputs":[],"source":["\n","def detect(image, text_prompt, model, box_threshold = 0.3, text_threshold = 0.25):\n","  boxes, logits, phrases = predict(\n","      model=model,\n","      image=image,\n","      caption=text_prompt,\n","      box_threshold=box_threshold,\n","      text_threshold=text_threshold\n","  )\n","\n","  annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n","  annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n","  return annotated_frame, boxes"]},{"cell_type":"markdown","metadata":{"id":"E_mj2y0LQHYV"},"source":["## SAM for Segmentation"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"LWb1Au-A1_2h","executionInfo":{"status":"ok","timestamp":1700594259327,"user_tz":-330,"elapsed":3,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"}}},"outputs":[],"source":["\n","\n","\n","def segment(image, sam_model, boxes):\n","  sam_model.set_image(image)\n","  H, W, _ = image.shape\n","  boxes_xyxy = box_ops.box_cxcywh_to_xyxy(boxes) * torch.Tensor([W, H, W, H])\n","\n","  transformed_boxes = sam_model.transform.apply_boxes_torch(boxes_xyxy.to(device), image.shape[:2])\n","  masks, _, _ = sam_model.predict_torch(\n","      point_coords = None,\n","      point_labels = None,\n","      boxes = transformed_boxes,\n","      multimask_output = False,\n","      )\n","  return masks.cpu()\n","\n","\n","def draw_mask(mask, image, random_color=True):\n","    if random_color:\n","        color = np.concatenate([np.random.random(3), np.array([0.8])], axis=0)\n","    else:\n","        color = np.array([30/255, 144/255, 255/255, 0.6])\n","    h, w = mask.shape[-2:]\n","    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n","\n","    annotated_frame_pil = Image.fromarray(image).convert(\"RGBA\")\n","    mask_image_pil = Image.fromarray((mask_image.cpu().numpy() * 255).astype(np.uint8)).convert(\"RGBA\")\n","\n","    return np.array(Image.alpha_composite(annotated_frame_pil, mask_image_pil))"]},{"cell_type":"markdown","metadata":{"id":"Vp17SG7W_IDG"},"source":["## Methods for Detection, Segmentation, Generating masks and Saving the output image\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"dBK3tSfoT9ES","executionInfo":{"status":"ok","timestamp":1700594263480,"user_tz":-330,"elapsed":1,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"}}},"outputs":[],"source":["def run_dino_detection(image_source, image):\n","\n","  annotated_frame, detected_boxes = detect(image, text_prompt=\"patty\", model=groundingdino_model)\n","  return annotated_frame, detected_boxes"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"IeEtoyC-YL0e","executionInfo":{"status":"ok","timestamp":1700594265322,"user_tz":-330,"elapsed":2,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"}}},"outputs":[],"source":["def run_sam_segmentation(image_source, image, annotated_frame, detected_boxes):\n","\n","  segmented_frame_masks = segment(image_source, sam_predictor, boxes=detected_boxes)\n","  annotated_frame_with_mask = draw_mask(segmented_frame_masks[0][0], annotated_frame)\n","  return annotated_frame_with_mask"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"PyE4GYMwzrAo","executionInfo":{"status":"ok","timestamp":1700594275568,"user_tz":-330,"elapsed":721,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"}}},"outputs":[],"source":["def generate_masked_image(annotated_frame, annotated_frame_with_mask):\n","  b = annotated_frame_with_mask[:, :, :3]\n","  are_equal = np.array_equal(annotated_frame, b)\n","\n","\n","  img = image_source.copy()\n","  mask = annotated_frame == b\n","\n","  img[mask] = 0\n","  return img"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"bGXrIn4R1awB","executionInfo":{"status":"ok","timestamp":1700594279768,"user_tz":-330,"elapsed":1026,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"}}},"outputs":[],"source":["def save_image(masked_image, save_folder_path, image_name):\n","  image = Image.fromarray(masked_image)\n","\n","  filename = f\"{image_name}\"\n","  save_image_path = os.path.join(save_folder_path, filename)\n","\n","  image.save(save_image_path, \"JPEG\")"]},{"cell_type":"markdown","metadata":{"id":"XEJmPWt-SjIL"},"source":["## Loading IMAGES from drive and running the methods\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"o2aBRxZm_BXx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700594330971,"user_tz":-330,"elapsed":39231,"user":{"displayName":"Badal Chowdhary","userId":"02077093592109328320"}},"outputId":"a99d5e38-3ace-4a49-be5c-9d9150c1632e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qzXCxZiVHzso"},"outputs":[],"source":["import os\n","from PIL import Image\n","import numpy as np\n","import random\n","from tqdm import tqdm\n","\n","image_folders_path = '/content/drive/MyDrive/Food Recognition Project/Resized Dataset'\n","\n","selected_classes = [\n"," 'commercial_deep_over',\n"," 'commercial_unbaked',\n"," 'inhouse_deep_normal',\n"," 'inhouse_deep_over',\n"," 'inhouse_old_deep_normal',\n"," 'inhouse_old_deep_over',\n"," 'inhouse_unbaked'\n"," 'commercial_deep_normal']\n","\n","save_directory = '/content/drive/MyDrive/Food Recognition Project/New_Dataset'\n","\n","for class_name in selected_classes:\n","\n","    class_folder_path = os.path.join(image_folders_path, class_name)\n","\n","    save_folder_path = os.path.join(save_directory, class_name)\n","    os.makedirs(save_folder_path, exist_ok=True)\n","\n","    if os.path.exists(class_folder_path):\n","\n","        class_images = os.listdir(class_folder_path)\n","\n","        for image_name in tqdm(class_images):\n","            image_path = os.path.join(class_folder_path, image_name)\n","            image_source, image = load_image(image_path)\n","\n","            annotated_frame, detected_boxes = run_dino_detection(image_source, image)\n","            annotated_frame_with_mask = run_sam_segmentation(image_source, image, annotated_frame, detected_boxes)\n","            masked_image = generate_masked_image(annotated_frame, annotated_frame_with_mask)\n","\n","            save_image(masked_image, save_folder_path, image_name)\n","\n","\n","    else:\n","        print(f\"Class folder not found: {class_folder_path}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zuf4UTQ1kH5m"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}